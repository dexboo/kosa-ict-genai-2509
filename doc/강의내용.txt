
# 강의 목표
생성형 AI에 사용되는 기술들에 대해서 전체적으로 이해하고 다양한 라이브러리와 연동하여 실제 필요한 서비스 구축 


## ChatGPT 개요 
- ChatGPT는 OpenAI에서 개발한 언어 모델(LLM)로 자연어 이해 및 생성에 대한 혁신적인 능력 제공 
- 대화형 인터페이스를 통해 사용자와 상호작용하며, 텍스트 기반의 질문 응답, 대화 생성, 자동 요약 등 다양한 언어 작업 수행 가능 
- 가입은 chatgpt.com, 무료계정은 ChatGPT로 모델이 고정, 한달에 $20의 비용을 지불하여 ChatGPT plus로 모델을 업그레이드 가능
- ChatGPT plus: 모델의 성능이 좀 더 우수하며, 여러가지 플러그인을 활용하여 대화 외에 좀더 상세한 작업에 사용 가능 
- 무료, 유료 모두 일정 수준의 request rate limit이 있으며, 그 이상의 요청에 대해서는 블록처리 
- API로도 접근가능하나 API는 사용하는 token 양에 비례하는 요금을 과금 
- 신용카드를 등록한 신규계정에 대해서는 3개월 기한의 $18 -> $5의 무료 크레딧이 제공되었으나 현재는 $0로 시작
- 일단 크레딧을 충전하고 난 후에 사용할 수 있음(최소 충전은 $5) 


## ChatGPT로 개발시 주의사항
- ChatGPT는 현재 나와 있는 언어 모델 중 가장 우수한 종류
- ChatGPT만으로 AI 서비스를 만들 수 없고 실제 서비스 구축을 위해서는 LLM 외 다른 요소들이 상당히 많이 필요
- ChatGPT를 실제 서비스에 적용하려면 부족한 점들이 존재하며, 가격이 내려감과 동시에 점점 더 성능이 낮아지고 API도 계속 변경되므로 변화에 지속적으로 대응 
- 사용량이 많아지면 그에 비례하여 비용이 증가하며, 채팅을 통해 회사 내부의 정보가 외부로 흘러나갈 수 있다는 점 고려
- 자체 인프라를 구축하거나 인터페이스에 필터를 적용할 수도 있음(가드레일) 
- AI 서비스를 구축하는 방법에 대해서는 비교적 잘 알려져 있으나, 서비스하기에 충분한 품질을 얻는 것은 생각보다 많이 어려움
- AI 서비스를 구축할 때는 반드시 원하는 성능 지표를 설정하고 측정을 위한 데이터셋을 준비해야 함
- ChatGPT의 비용은 성능을 고려할 때 매우 낮은 편이나, 만약 호출이 매우 많아지거나 context를 매번 길게 사용하면 비용은 빠르게 증가
- 항상 상위 모델을 사용 할 필요는 없으며 적절한 모델을 선택하면 이런 비용은 최적화될 수 있음


## OpenAI API 연동
- https://platform.openai.com/ 에 접속하여 가입하고 카드 등록 (Google, Apple, MS 계정으로 가입 가능) 
- token 사용량에 따라 다음 달에 과금하는 구조였으나, Credit Balance에서 충전하고 이를 소진하는 방식으로 변경
- Credit Balance가 $0.0이 되면 rate limit이 걸렸을 때와 유사하게 429 에러가 발생 (최소 충전금액은 $5)
- Auto recharge 옵션을 적용시키면 Credit Balance가 일정 수준 이하로 떨어졌을 때 자동으로 일정액씩 충전 가능 
- API key를 생성하여 연동할 수 있으며 한번 생성된 key는 다시 보여지지 않음(삭제 후 재생성) 
- 사용을 위해 python의 openai 패키지 설치가 필요(pip3 install openai)
- 주로 사용하는 모델: gpt-4o-mini, gpt-5-nano, gpt-5-mini, 비교용으로 gpt-3.5-turbo


## OpenAI API vs Azure OpenAI Service
- MS Azure 클라우드에서도 거의 동일한 모델들을 거의 동일한 가격으로 판매 
- MS Azure OpenAI Service의 장점은 US West 단일지역이 아닌 다른지역(도쿄) 선택가능, 여러 클라우드의 보안조치가 되어있음
- Azure OpenAI 모델의 지역 할당량: gpt-3.5-turbo모델(분당120K~300K), gpt-4(20~40K)
- 할당량이 부족해지면 Azure 포털에서 할당량 증가 요청 가능하며, 수락되면 더 많은 token을 사용 가능
- OpenAI를 대규모 서비스에 적용할 경우 가장 문제가 되는 부분이 할당량 quota 
- MS Azure의 OpenAI 모델은 별도의 폼으로 신청해야 하며 Azure의 체험 계정으로는 사용 어려움


## WSL2 
- ChatGPT는 API만 연결하면 되므로 특정 환경에 구애받지 않음 
- 다만 결과를 확인하기 위해서는 좀더 interactive한 환경이 적합(jupyter notebook 또는 Google colab)
- Google colab 세션은 계속 유지되지 않으므로 사용하기에 적당하지 않으며, git repo 연동도 어려움 
- 이 과정에서는 로컬 PC에 wsl을 설치하고, wsl에서 python환경을 구축한 후 jupyter notebook 실행 
- WSL2(Windows Subsystem for Linux2)는 윈도우에서 리눅스 어플리케이션을 구동하게 해주는 호환성 레이어로 리눅스 커널 기능 제공 
- WSL2를 사용하면 윈도우안에서 리눅스 배포본을 구동하여 리눅스 어플리케이션 실행 가능, 거의 대부분의 어플리케이션을 무리 없이 실행 가능 
- 여러가지 오픈소스 프로젝트들이 리눅스를 기준하여 개발되고 있으므로, 윈도우에서의 설치로는 한계
- 가상화 기능이 있는 Windows 10 이상의 PC에서는 모두 사용 가능
- Mac 사용자는 wsl을 사용할 필요가 없으며 자체적으로 python과 pip, jupyter, git을 설치해서 사용 



-----------------------------------------------------------------------

## Completion mode (depreciated), 지시와 명령을 하나의 prompt로 전달 
import os 
import openai 
openai.api_key = os.getenv("OPENAI_API_KEY") 
response = openai.completions.create(		# 텍스트 생성 요청을 보냅니다. 
	model="gpt-3.5-turbo-instruct",  
	prompt="다음을 일본어로 번역하세요: 안녕하세요? 오늘 날씨가 참 좋군요!", 
	max_tokens=256,		# 생성된 텍스트의 최대 길이를 설정합니다. 
) 
print(response.choices[0].text) 		# 생성된 텍스트를 출력합니다. 


## 표준적인 Chat completion mode 
import openai 
res = openai.chat.completions.create( 
	model="gpt-4o-mini",  
	messages=[{"role": "user", "content": "다음을 일본어로 번역하세요: 안녕하세요? 오늘 날씨가 참 좋군요!"}], 
	temperature=0.5, 
	max_tokens=256, 
	top_p=1, 
	frequency_penalty=0, 
	presence_penalty=0,
	stream=True,		# 스트리밍 모드
) 
print(res.choices[0].message.content)		# 일반 모드인 경우, 출력

while True:		# 스트리밍 모드인 경우, 순차적으로 출력
	response = next(res) 
	delta = response.choices[0].delta 
	if delta.content is not None: 
		print(delta.content, end='') 
	else: 
		break 



## OpenAI의 role 
- system: 주로 채팅 대화의 시작 부분에 사용, 시스템 역할로 제공된 메시지는 Assistant에게 초기 컨텍스트를 제공하고 작동 방식 지정 
	예) 당신은 과학에 대한 전문가입니다. 
- user: 사용자 역할은 API를 호출하는 클라이언트 측 역할, Assistant에게 질문을 하거나 지시를 내릴 때 사용
	예) 과학 분야에서 어떤 발전이 있었나요? 
- assistant: 사용자 역할로부터 받은 메시지에 대답하고 정보를 제공하는 역할
	예) 새로운 에너지 저장 기술에 대해 이야기해드릴게요. 
- function: Assistant가 호출로 실행한 작업을 정의할 때 사용, 주로 외부의 API와 LLM을 연동하기 위한 목적으로 사용


## Hyper parameters (Chat mode 기준) 
- temperature: 생성시 다양성을 조절하는 매개변수(0~1) 
- max_tokens: 생성된 텍스트의 최대 토큰 수 
- stop: 종료 토큰(End-of-Sequence)을 나타내는 토큰의 리스트 
- top_p: 다음 단어 선택시 고려되는 확률 분포의 크기를 지정하는 매개변수(0.1~1), 0.8은 상위 80%의 확률인 token 중 다음 단어 선택 
- frequency_penalty: 단어 반복에 대해서 패널티를 주어서 반복하지 않게 하는 매개변수 
- presence_penalty: 새 토큰에 대한 출현빈도를 낮추기 위한 매개변수 



-----------------------------------------------------------------------

## 프롬프트 엔지니어링 
- 다양한 애플리케이션과 연구 주제에 언어모델(LM)을 효율적으로 사용할 수 있도록 프롬프트를 개발하고 최적화하는 비교적 새로운 분야
- 연구자는 프롬프트 엔지니어링을 사용하여 질의응답 및 산술 추론과 같은 일반적 작업부터 복잡한 작업까지 다양한 범위에서 LLM의 역량을 향상
- 프롬프트 엔지니어링은 LLM과 상호 작용하고 개발하는데 유용한 다양한 기술과 기법을 포함 
- LLM과 인터페이스를 형성하고, 빌드하고, LLM의 기능을 이해하는 데 중요한 기술 
- LLM에 따라 프롬프트의 유효성은 차이가 있음 (대부분의 프롬프트 엔지니어링은 ChatGPT를 기준으로 설명)
- llama나 다른 LLM 들에는 잘 적용되지 않을 수 있음, 작은 모델일수록 상세한 프롬프트를 잘 이해하지 못하는 경향


## CoT(Chain of Thought) 
- LLM이 최종 답변을 내리기 전에 중간 추론 단계를 명시적으로 보여주는 프롬프팅 기법 
- 복잡한 문제 해결력 향상, 추론 과정의 투명성 확보 등의 장점 
- "Let's solve this step by step" 같은 명시적 지시어 사용, 중간 사고 과정 표현 
- 수학 문제 해결, 논리 추론, 의사결정, 코딩 문제 등에 사용 
- Zero-shot CoT, Few-shot CoT, Self-consistency CoT 등 다양한 변형 기법 개발 
- 최근에는 LLM 자체를 CoT 형식의 데이터로 학습한 모델들도 나오고 있음, 추론(reasoning) 모델이라고도 함 
- CoT에 맞게 학습된 o1계열 모델(o1-mini와 o1-preview)들은 CoT 프롬프트를 쓰지 않는 편이 오히려 좋은 결과가 나올 가능성을 높임 



-----------------------------------------------------------------------

## 실습
# 실습1: 
삼성전자의 주가 데이터를 가져와서 분석하는 ChatGPT 어플리케이션을 작성하시오(힌트: pykrx 패키지)

# 실습2: 
사용자가 입력한 질문에 맞는 캠핑장을 검색해서 추천하는 ChatGPT 어플리케이션을 작성하시오(힌트: 고캠핑 API) 
예) 수영장이 있는 캠핑장을 추천해줘.



### 주가 API: pykrx
https://github.com/sharebook-kr/pykrx


### 고캠핑 API: 한국관광공사_고캠핑 정보 조회서비스_GW
https://www.data.go.kr/data/15101933/openapi.do






